"""
ğŸš€ Main Pipeline - è³‡é‡‘æµå‘æ•¸æ“šç®¡é“ v1.0
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
åŠŸèƒ½ç‰¹è‰²ï¼š
- æ•´åˆ ChainAnalyzer å’Œ CEXAnalyzer åŸ·è¡Œåˆ†æ
- è¼¸å‡º data.json (å³æ™‚å¿«ç…§)
- è¿½åŠ  history.csv (æ­·å²æ•¸æ“šä¾›å›æ¸¬)
- ç´”æ•¸æ“šè¼¸å‡ºï¼Œç„¡ HTML ç”Ÿæˆ

è¼¸å‡ºï¼š
- reports/data.json: å®Œæ•´å¿«ç…§æ•¸æ“š
- reports/history.csv: æ­·å²è¿½è¹¤è¡Œ
"""

import asyncio
import json
import csv
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any

from data_provider import DataProvider
from analyzer_chain import ChainAnalyzer
from analyzer_cex import CEXAnalyzer
from notification_service import check_and_alert, send_summary_notification

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è¼¸å‡ºè·¯å¾‘
REPORTS_DIR = Path(__file__).parent / "reports"
DATA_JSON_PATH = REPORTS_DIR / "data.json"
HISTORY_CSV_PATH = REPORTS_DIR / "history.csv"

# åˆ†æçš„å…¬éˆåˆ—è¡¨
CHAINS_TO_ANALYZE = [
    'ethereum', 'solana', 'bsc', 'arbitrum', 'base',
    'polygon', 'avalanche', 'optimism', 'tron'
]

# CSV æ¬„ä½å®šç¾©
CSV_COLUMNS = [
    'Timestamp',
    'Total_Stablecoin_MarketCap',
    'Binance_Net_Flow',
    'Solana_TVL',
    'Ethereum_TVL'
]


async def run_pipeline() -> Dict[str, Any]:
    """
    åŸ·è¡Œå®Œæ•´æ•¸æ“šç®¡é“
    
    Returns:
        èšåˆå¾Œçš„æ•¸æ“šå¿«ç…§
    """
    logger.info("ğŸš€ å•Ÿå‹•è³‡é‡‘æµå‘æ•¸æ“šç®¡é“...")
    start_time = datetime.now()
    
    async with DataProvider() as provider:
        # 1. åŸ·è¡Œå…¬éˆåˆ†æ
        logger.info("ğŸ“Š åˆ†æå…¬éˆè³‡é‡‘æµå‘...")
        chain_analyzer = ChainAnalyzer(provider)
        chain_data = await chain_analyzer.analyze_multiple_chains(CHAINS_TO_ANALYZE)
        
        # 2. åŸ·è¡Œäº¤æ˜“æ‰€åˆ†æ
        logger.info("ğŸ¦ åˆ†æäº¤æ˜“æ‰€è³‡é‡‘æµå‘...")
        cex_analyzer = CEXAnalyzer(provider)
        cex_data = await cex_analyzer.analyze_multiple_exchanges()
        
        # 3. ç²å–ç©©å®šå¹£å¸‚å€¼
        logger.info("ğŸ’µ ç²å–ç©©å®šå¹£å¸‚å€¼...")
        stablecoin_marketcap = await _get_stablecoin_marketcap(provider)

        # 4. ç²å–è¡ç”Ÿå“æ•¸æ“š (Institutional Grade)
        logger.info("ğŸ“ˆ ç²å–è¡ç”Ÿå“æ•¸æ“š (Funding/OI)...")
        derivs_data = await provider.get_derivatives_data()

        # 5. ç²å–å¸‚å ´æƒ…ç·’æŒ‡æ¨™ (Macro)
        logger.info("ğŸ˜¨ ç²å–ææ…Œè²ªå©ªæŒ‡æ•¸...")
        fng_data = await provider.fetch_fear_greed_index()
    
    # 6. ç”Ÿæˆçµ±ä¸€å ±å‘Š
    from report_generator import ReportGenerator
    
    logger.info("ğŸ“ ç”Ÿæˆçµ±ä¸€å ±å‘Š (V2 Schema)...")
    
    # è¨ˆç®—åŠ æ¬Šæƒ…ç·’ (Phase 3: AI Sentiment Weighting)
    sentiment_details = _calculate_sentiment_score(
        chain_data, 
        cex_data, 
        derivs_data, 
        fng_data
    )
    
    generator = ReportGenerator()
    unified_report = generator.generate_unified_report(
        chain_data=chain_data,
        cex_data=cex_data,
        sentiment_details=sentiment_details,
        stablecoin_marketcap=stablecoin_marketcap,
        derivs_data=derivs_data,
        fng_data=fng_data  # Pass Macro Data
    )
    
    # æ·»åŠ åŸ·è¡Œæ™‚é–“
    unified_report['meta']['execution_time_seconds'] = (datetime.now() - start_time).total_seconds()
    
    # 5. å„²å­˜è¼¸å‡º
    await _save_outputs(unified_report, chain_data, cex_data, stablecoin_marketcap)
    
    # 6. ç™¼é€ Discord é€šçŸ¥
    logger.info("ğŸ”” æª¢æŸ¥ä¸¦ç™¼é€ Discord è­¦å ±...")
    alerts_sent = check_and_alert(unified_report)  # ç¢ºä¿ check_and_alert èƒ½è™•ç†æ–°æ ¼å¼
    if alerts_sent > 0:
        logger.info(f"   â†’ å·²ç™¼é€ {alerts_sent} å€‹è­¦å ±")
    
    # 7. ç™¼é€æ‘˜è¦é€šçŸ¥
    send_summary_notification(unified_report)
    
    logger.info(f"âœ… ç®¡é“åŸ·è¡Œå®Œæˆ ({unified_report['meta']['execution_time_seconds']:.2f}s)")
    
    return unified_report


async def _get_stablecoin_marketcap(provider: DataProvider) -> float:
    """
    ç²å–ç©©å®šå¹£ç¸½å¸‚å€¼
    """
    try:
        data = await provider.get_stablecoins()
        if data and 'peggedAssets' in data:
            total = 0
            for asset in data['peggedAssets']:
                circulating = asset.get('circulating', {})
                total += circulating.get('peggedUSD', 0) or 0
            return total
    except Exception as e:
        logger.warning(f"ç„¡æ³•ç²å–ç©©å®šå¹£å¸‚å€¼: {e}")
    return 0


def _calculate_sentiment_score(
    chain_data: Dict, 
    cex_data: Dict, 
    derivs_data: Dict = None, 
    fng_data: Dict = None
) -> Dict[str, Any]:
    """
    åŠ æ¬Šæƒ…ç·’è©•åˆ†ç³»çµ± V3 (AI Weighted Model)
    åŒ…å«: Smart Money Flow, Derivatives Structure, Macro Sentiment
    """
    derivs_data = derivs_data or {}
    fng_data = fng_data or {}
    factors = []
    total_score = 0
    
    # 1. Smart Money Flow (æ¬Šé‡ 40%) - æœ€é‡è¦æŒ‡æ¨™
    sm_flow = cex_data.get('summary', {}).get('smart_money_stable_flow', 0)
    score_sm = 0
    if sm_flow > 50_000_000: score_sm = 100    # Strong Buy
    elif sm_flow > 10_000_000: score_sm = 75   # Buy
    elif sm_flow > 0: score_sm = 25            # Weak Buy
    elif sm_flow < -50_000_000: score_sm = -100 # Strong Sell
    elif sm_flow < -10_000_000: score_sm = -75  # Sell
    elif sm_flow < 0: score_sm = -25            # Weak Sell
    
    total_score += score_sm * 0.4
    factors.append({
        'name': 'ä¸»åŠ›å‹•å‘ (Smart Money)',
        'score': score_sm,
        'weight': '40%',
        'value': f"${sm_flow/1e6:+.1f}M"
    })
    
    # 2. Derivatives Structure (æ¬Šé‡ 30%)
    funding_btc = derivs_data.get('funding_rates', {}).get('BTC', 0.01)
    score_derivs = 0
    if funding_btc > 0.03: score_derivs = -80      # æ¥µåº¦éç†±
    elif funding_btc > 0.01: score_derivs = -40    # åå¤šéç†±
    elif funding_btc < -0.01: score_derivs = 60    # è»‹ç©ºé æœŸ
    elif funding_btc < -0.02: score_derivs = 90    # å¼·çƒˆè»‹ç©ºé æœŸ
    else: score_derivs = 10                        # ä¸­æ€§åå¤š (å¥åº·è²»ç‡)
    
    total_score += score_derivs * 0.3
    factors.append({
        'name': 'åˆç´„çµæ§‹ (Derivatives)',
        'score': score_derivs,
        'weight': '30%',
        'value': f"Funding {funding_btc*100:.4f}%"
    })
    
    # 3. Chain Activity (20%)
    chain_summary = chain_data.get('summary', {})
    chain_flow = chain_summary.get('stablecoin_flow_24h', 0)
    score_chain = 0
    if chain_flow > 20_000_000: score_chain = 100
    elif chain_flow > 0: score_chain = 50
    else: score_chain = -50
    
    total_score += score_chain * 0.2
    factors.append({
        'name': 'å…¬éˆç”Ÿæ…‹ (On-chain)',
        'score': score_chain,
        'weight': '20%',
        'value': f"${chain_flow/1e6:+.1f}M"
    })
    
    # 4. Macro Sentiment (Contra) (10%)
    fng_val = fng_data.get('value', 50)
    score_macro = 0
    # é€†å‹¢é‚è¼¯: æ¥µåº¦ææ…Œ(20)æ˜¯è²·é»(+80åˆ†)
    if fng_val < 20: score_macro = 80       
    elif fng_val < 40: score_macro = 40     
    elif fng_val > 80: score_macro = -80    
    elif fng_val > 60: score_macro = -40    
    
    total_score += score_macro * 0.1
    factors.append({
        'name': 'å¸‚å ´æƒ…ç·’ (Sentiment)',
        'score': score_macro,
        'weight': '10%',
        'value': f"F&G {fng_val}"
    })
    
    # æœ€çµ‚è©•ç´š
    label = 'Neutral'
    if total_score >= 60: label = 'Strong Bullish ğŸš€'
    elif total_score >= 20: label = 'Bullish ğŸŸ¢'
    elif total_score <= -60: label = 'Strong Bearish ğŸ©¸'
    elif total_score <= -20: label = 'Bearish ğŸ”´'
    
    return {
        'score': round(total_score, 1),
        'label': label,
        'factors': factors
    }


def _determine_overall_sentiment(chain_data: Dict, cex_data: Dict) -> str:
    """
    ç¶œåˆåˆ¤æ–·å¸‚å ´æƒ…ç·’ (å‘å¾Œå…¼å®¹åŒ…è£å‡½æ•¸)
    """
    result = _calculate_sentiment_score(chain_data, cex_data)
    return result['label']


async def _save_outputs(
    snapshot: Dict, 
    chain_data: Dict, 
    cex_data: Dict, 
    stablecoin_marketcap: float
):
    """
    å„²å­˜è¼¸å‡ºæ–‡ä»¶
    """
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    REPORTS_DIR.mkdir(exist_ok=True)
    
    # 1. å„²å­˜ data.json
    logger.info(f"ğŸ’¾ å„²å­˜å¿«ç…§åˆ° {DATA_JSON_PATH}...")
    with open(DATA_JSON_PATH, 'w', encoding='utf-8') as f:
        json.dump(snapshot, f, indent=2, ensure_ascii=False)
    
    # 2. è¿½åŠ  history.csv
    logger.info(f"ğŸ“ è¿½åŠ æ­·å²è¨˜éŒ„åˆ° {HISTORY_CSV_PATH}...")
    _append_history_csv(chain_data, cex_data, stablecoin_marketcap)


def _append_history_csv(chain_data: Dict, cex_data: Dict, stablecoin_marketcap: float):
    """
    è¿½åŠ ä¸€è¡Œåˆ° history.csv
    """
    # æå–æ‰€éœ€æ•¸æ“š
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # å¾ chain_data æå– Solana å’Œ Ethereum TVL
    solana_tvl = 0
    ethereum_tvl = 0
    for chain in chain_data.get('chains', []):
        if chain.get('chain') == 'solana':
            solana_tvl = chain.get('tvl_total', 0)
        elif chain.get('chain') == 'ethereum':
            ethereum_tvl = chain.get('tvl_total', 0)
    
    # å¾ cex_data æå– Binance æ·¨æµå…¥
    binance_net_flow = 0
    for exchange in cex_data.get('exchanges', []):
        if exchange.get('exchange') == 'binance-cex':
            binance_net_flow = exchange.get('net_flow_24h', 0)
            break
    
    # æ§‹å»ºè¡Œæ•¸æ“š
    row = {
        'Timestamp': timestamp,
        'Total_Stablecoin_MarketCap': stablecoin_marketcap,
        'Binance_Net_Flow': binance_net_flow,
        'Solana_TVL': solana_tvl,
        'Ethereum_TVL': ethereum_tvl
    }
    
    # æª¢æŸ¥ CSV æ˜¯å¦å­˜åœ¨
    file_exists = HISTORY_CSV_PATH.exists()
    
    with open(HISTORY_CSV_PATH, 'a', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=CSV_COLUMNS)
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯«å…¥æ¨™é¡Œè¡Œ
        if not file_exists:
            writer.writeheader()
        
        writer.writerow(row)
    
    logger.info(f"   â†’ å·²è¿½åŠ : Stablecoin ${stablecoin_marketcap/1e9:.1f}B, "
                f"Binance Flow ${binance_net_flow/1e6:+.1f}M, "
                f"SOL TVL ${solana_tvl/1e9:.1f}B, ETH TVL ${ethereum_tvl/1e9:.1f}B")


def main():
    """
    ä¸»å…¥å£
    """
    print("=" * 60)
    print("ğŸš€ è³‡é‡‘æµå‘æ•¸æ“šç®¡é“ (Capital Flow Pipeline)")
    print("=" * 60)
    
    snapshot = asyncio.run(run_pipeline())
    
    print("\n" + "=" * 60)
    print("ğŸ“Š åŸ·è¡Œçµæœæ‘˜è¦")
    print("=" * 60)
    # V2 Schema Output
    try:
        print(f"   å¸‚å ´æƒ…ç·’: {snapshot['market_overview']['sentiment']['label']}")
        print(f"   ç©©å®šå¹£å¸‚å€¼: ${snapshot['market_overview']['stablecoin_marketcap']/1e9:.1f}B")
        print(f"   åˆ†æå…¬éˆæ•¸: {snapshot['market_overview']['total_tvl']['dex']:.0f} (Total TVL)") # Simplify print
        print(f"   åˆ†æäº¤æ˜“æ‰€æ•¸: {snapshot['cex_analysis']['summary']['exchange_count']}")
    except KeyError:
        # Fallback for older schema or partial data
        print("   (Summary data format changed, check data.json)")
    
    print(f"   åŸ·è¡Œæ™‚é–“: {snapshot['meta']['execution_time_seconds']:.2f}s")
    print("=" * 60)
    print("ğŸ“ è¼¸å‡ºæ–‡ä»¶:")
    print(f"   â†’ {DATA_JSON_PATH}")
    print(f"   â†’ {HISTORY_CSV_PATH}")
    print("=" * 60)


if __name__ == '__main__':
    main()
