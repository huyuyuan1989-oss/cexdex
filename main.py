"""
ğŸš€ Main Pipeline - è³‡é‡‘æµå‘æ•¸æ“šç®¡é“ v1.0
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
åŠŸèƒ½ç‰¹è‰²ï¼š
- æ•´åˆ ChainAnalyzer å’Œ CEXAnalyzer åŸ·è¡Œåˆ†æ
- è¼¸å‡º data.json (å³æ™‚å¿«ç…§)
- è¿½åŠ  history.csv (æ­·å²æ•¸æ“šä¾›å›æ¸¬)
- ç´”æ•¸æ“šè¼¸å‡ºï¼Œç„¡ HTML ç”Ÿæˆ

è¼¸å‡ºï¼š
- reports/data.json: å®Œæ•´å¿«ç…§æ•¸æ“š
- reports/history.csv: æ­·å²è¿½è¹¤è¡Œ
"""

import asyncio
import json
import csv
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any

from data_provider import DataProvider
from analyzer_chain import ChainAnalyzer
from analyzer_cex import CEXAnalyzer
from notification_service import check_and_alert, send_summary_notification
from report_generator import ReportGenerator
from paper_trader import PaperTrader
from analyzer_social import SocialSentimentAnalyzer 
from market_agents import HiveMind # V7 Feature
from rl_optimizer import RLOptimizer # V7 RL Core
from yield_farmer import YieldFarmer # V7 Omni-Chain Yield

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è¼¸å‡ºè·¯å¾‘
REPORTS_DIR = Path(__file__).parent / "reports"
DATA_JSON_PATH = REPORTS_DIR / "data.json"
HISTORY_CSV_PATH = REPORTS_DIR / "history.csv"

# åˆ†æçš„å…¬éˆåˆ—è¡¨
CHAINS_TO_ANALYZE = [
    'ethereum', 'solana', 'bsc', 'arbitrum', 'base',
    'polygon', 'avalanche', 'optimism', 'tron'
]

# CSV æ¬„ä½å®šç¾©
CSV_COLUMNS = [
    'Timestamp',
    'Total_Stablecoin_MarketCap',
    'Binance_Net_Flow',
    'Solana_TVL',
    'Ethereum_TVL'
]


async def run_pipeline() -> Dict[str, Any]:
    """
    åŸ·è¡Œå®Œæ•´æ•¸æ“šç®¡é“ (End-to-End Pipeline)
    """
    start_time = datetime.now()
    logger.info("ğŸš€ å•Ÿå‹•è³‡é‡‘æµå‘æ•¸æ“šç®¡é“...")
    
    # åˆå§‹åŒ–çµ„ä»¶
    provider = DataProvider()
    analyzer_chain = ChainAnalyzer(provider)
    analyzer_cex = CEXAnalyzer(provider)
    generator = ReportGenerator()
    social_analyzer = SocialSentimentAnalyzer() # V5
    paper_trader = PaperTrader(provider) # V6 Simulation
    hive_mind = HiveMind() # V7
    rl_optimizer = RLOptimizer()
    yield_farmer = YieldFarmer()
    
    async with provider:
        # 1. ä¸¦è¡Œç²å–æ•¸æ“š
        logger.info("ğŸ“Š åˆ†æå…¬éˆè³‡é‡‘æµå‘...")
        chain_task = analyzer_chain.analyze_multiple_chains(CHAINS_TO_ANALYZE)
        
        logger.info("ğŸ¦ åˆ†æäº¤æ˜“æ‰€è³‡é‡‘æµå‘...")
        cex_task = analyzer_cex.analyze_multiple_exchanges()
        
        # ä¸¦è¡ŒåŸ·è¡Œä¸»è¦åˆ†æä»»å‹™
        chain_data, cex_data = await asyncio.gather(chain_task, cex_task)
        
        # 2. ç²å–è¼”åŠ©æ•¸æ“š
        logger.info("ğŸ’µ ç²å–ç©©å®šå¹£å¸‚å€¼...")
        stablecoin_data = await provider.get_stablecoins()
        if stablecoin_data and 'peggedAssets' in stablecoin_data:
            stablecoin_marketcap = sum(a.get('circulating', {}).get('peggedUSD', 0) or 0 for a in stablecoin_data['peggedAssets'])
        else:
            stablecoin_marketcap = 0
            
        logger.info("ğŸ“ˆ ç²å–è¡ç”Ÿå“æ•¸æ“š (Funding/OI)...")
        derivs_data = await provider.get_derivatives_data() 
        
        logger.info("ğŸ˜¨ ç²å–ææ…Œè²ªå©ªæŒ‡æ•¸...")
        fng_data = await provider.fetch_fear_greed_index()

        # 3. [V5 Feature] Social Sentiment Analysis
        logger.info("ğŸ¦ V5 Intelligence: Analyzing Social Sentiment...")
        tokens_to_analyze = set()
        for chain in chain_data.get('chains', []):
            if 'top_protocols' in chain:
                for p in chain['top_protocols']:
                    if p.get('symbol'):
                        tokens_to_analyze.add(p['symbol'])
        
        social_map = {}
        for token in tokens_to_analyze:
            sentiment = await social_analyzer.analyze_token_sentiment(token)
            social_map[token] = sentiment
            if sentiment['score'] > 60:
                logger.info(f"   ğŸ”¥ Hot Sentiment detected for {token}: {sentiment['narrative']}")

        # 4. ç”Ÿæˆçµ±ä¸€å ±å‘Š
        logger.info("ğŸ“ ç”Ÿæˆçµ±ä¸€åˆ†æå ±å‘Š...")
        unified_report = generator.generate_unified_report(
            chain_data=chain_data, 
            cex_data=cex_data, 
            stablecoin_marketcap=stablecoin_marketcap,
            derivs_data=derivs_data,
            fng_data=fng_data,
            social_data=social_map # Pass V5 Intel
        )
        unified_report['meta']['execution_time_seconds'] = (datetime.now() - start_time).total_seconds()
        
        # 5. [V7 Feature] The Hive Mind Debate
        if 'alpha_opportunities' in unified_report:
            logger.info("ğŸ§  V7 Hive Mind: Running Agent Debate...")
            
            # Prepare Global Context
            context = {
                'fng_val': fng_data.get('value', 50),
                'funding_btc': derivs_data.get('funding_rates', {}).get('BTC', 0)
            }
            
            for opp in unified_report['alpha_opportunities']:
                debate_result = hive_mind.debate(opp, context)
                opp['hive_analysis'] = debate_result # Inject V7 Result
                
        
        # 6. [V6 Feature] Paper Trading Simulation
        logger.info("ğŸ¤– åŸ·è¡Œæ¨¡æ“¬äº¤æ˜“å¼•æ“ (Paper Trading)...")
        await paper_trader.update_positions() # Update PnL for dirty positions
        
        # 6.1 [V7 Feature] RL Core Optimization
        # Run optimization *after* updating positions to learn from latest PnL
        rl_optimizer.run_optimization()
        
        if 'alpha_opportunities' in unified_report:
            await paper_trader.execute_signals(unified_report['alpha_opportunities'])
            
        # 6.2 [V7 Feature] Yield Farming
        active_pos_count = len([p for p in paper_trader.positions if p['status'] == 'OPEN'])
        yield_data = yield_farmer.optimize_idle_capital(active_pos_count)
        unified_report['yield_farming'] = yield_data
    
    # 7. å„²å­˜è¼¸å‡º
    await _save_outputs(unified_report, chain_data, cex_data, stablecoin_marketcap)
    
    # 8. ç™¼é€ Discord é€šçŸ¥
    logger.info("ğŸ”” æª¢æŸ¥ä¸¦ç™¼é€ Discord è­¦å ±...")
    alerts_sent = check_and_alert(unified_report)
    if alerts_sent > 0:
        logger.info(f"   â†’ å·²ç™¼é€ {alerts_sent} å€‹è­¦å ±")
    
    # 8. ç™¼é€æ‘˜è¦é€šçŸ¥
    send_summary_notification(unified_report)
    
    logger.info(f"âœ… ç®¡é“åŸ·è¡Œå®Œæˆ ({unified_report['meta']['execution_time_seconds']:.2f}s)")
    
    return unified_report


async def _get_stablecoin_marketcap(provider: DataProvider) -> float:
    """
    ç²å–ç©©å®šå¹£ç¸½å¸‚å€¼
    """
    try:
        data = await provider.get_stablecoins()
        if data and 'peggedAssets' in data:
            total = 0
            for asset in data['peggedAssets']:
                circulating = asset.get('circulating', {})
                total += circulating.get('peggedUSD', 0) or 0
            return total
    except Exception as e:
        logger.warning(f"ç„¡æ³•ç²å–ç©©å®šå¹£å¸‚å€¼: {e}")
    return 0


def _calculate_sentiment_score(
    chain_data: Dict, 
    cex_data: Dict, 
    derivs_data: Dict = None, 
    fng_data: Dict = None
) -> Dict[str, Any]:
    """
    åŠ æ¬Šæƒ…ç·’è©•åˆ†ç³»çµ± V3 (AI Weighted Model)
    åŒ…å«: Smart Money Flow, Derivatives Structure, Macro Sentiment
    """
    derivs_data = derivs_data or {}
    fng_data = fng_data or {}
    factors = []
    total_score = 0
    
    # 1. Smart Money Flow (æ¬Šé‡ 40%) - æœ€é‡è¦æŒ‡æ¨™
    sm_flow = cex_data.get('summary', {}).get('smart_money_stable_flow', 0)
    score_sm = 0
    if sm_flow > 50_000_000: score_sm = 100    # Strong Buy
    elif sm_flow > 10_000_000: score_sm = 75   # Buy
    elif sm_flow > 0: score_sm = 25            # Weak Buy
    elif sm_flow < -50_000_000: score_sm = -100 # Strong Sell
    elif sm_flow < -10_000_000: score_sm = -75  # Sell
    elif sm_flow < 0: score_sm = -25            # Weak Sell
    
    total_score += score_sm * 0.4
    factors.append({
        'name': 'ä¸»åŠ›å‹•å‘ (Smart Money)',
        'score': score_sm,
        'weight': '40%',
        'value': f"${sm_flow/1e6:+.1f}M"
    })
    
    # 2. Derivatives Structure (æ¬Šé‡ 30%)
    funding_btc = derivs_data.get('funding_rates', {}).get('BTC', 0.01)
    score_derivs = 0
    if funding_btc > 0.03: score_derivs = -80      # æ¥µåº¦éç†±
    elif funding_btc > 0.01: score_derivs = -40    # åå¤šéç†±
    elif funding_btc < -0.01: score_derivs = 60    # è»‹ç©ºé æœŸ
    elif funding_btc < -0.02: score_derivs = 90    # å¼·çƒˆè»‹ç©ºé æœŸ
    else: score_derivs = 10                        # ä¸­æ€§åå¤š (å¥åº·è²»ç‡)
    
    total_score += score_derivs * 0.3
    factors.append({
        'name': 'åˆç´„çµæ§‹ (Derivatives)',
        'score': score_derivs,
        'weight': '30%',
        'value': f"Funding {funding_btc*100:.4f}%"
    })
    
    # 3. Chain Activity (20%)
    chain_summary = chain_data.get('summary', {})
    chain_flow = chain_summary.get('stablecoin_flow_24h', 0)
    score_chain = 0
    if chain_flow > 20_000_000: score_chain = 100
    elif chain_flow > 0: score_chain = 50
    else: score_chain = -50
    
    total_score += score_chain * 0.2
    factors.append({
        'name': 'å…¬éˆç”Ÿæ…‹ (On-chain)',
        'score': score_chain,
        'weight': '20%',
        'value': f"${chain_flow/1e6:+.1f}M"
    })
    
    # 4. Macro Sentiment (Contra) (10%)
    fng_val = fng_data.get('value', 50)
    score_macro = 0
    # é€†å‹¢é‚è¼¯: æ¥µåº¦ææ…Œ(20)æ˜¯è²·é»(+80åˆ†)
    if fng_val < 20: score_macro = 80       
    elif fng_val < 40: score_macro = 40     
    elif fng_val > 80: score_macro = -80    
    elif fng_val > 60: score_macro = -40    
    
    total_score += score_macro * 0.1
    factors.append({
        'name': 'å¸‚å ´æƒ…ç·’ (Sentiment)',
        'score': score_macro,
        'weight': '10%',
        'value': f"F&G {fng_val}"
    })
    
    # æœ€çµ‚è©•ç´š
    label = 'Neutral'
    if total_score >= 60: label = 'Strong Bullish ğŸš€'
    elif total_score >= 20: label = 'Bullish ğŸŸ¢'
    elif total_score <= -60: label = 'Strong Bearish ğŸ©¸'
    elif total_score <= -20: label = 'Bearish ğŸ”´'
    
    return {
        'score': round(total_score, 1),
        'label': label,
        'factors': factors
    }


def _determine_overall_sentiment(chain_data: Dict, cex_data: Dict) -> str:
    """
    ç¶œåˆåˆ¤æ–·å¸‚å ´æƒ…ç·’ (å‘å¾Œå…¼å®¹åŒ…è£å‡½æ•¸)
    """
    result = _calculate_sentiment_score(chain_data, cex_data)
    return result['label']


async def _save_outputs(
    snapshot: Dict, 
    chain_data: Dict, 
    cex_data: Dict, 
    stablecoin_marketcap: float
):
    """
    å„²å­˜è¼¸å‡ºæ–‡ä»¶
    """
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    REPORTS_DIR.mkdir(exist_ok=True)
    
    # 1. å„²å­˜ data.json
    logger.info(f"ğŸ’¾ å„²å­˜å¿«ç…§åˆ° {DATA_JSON_PATH}...")
    with open(DATA_JSON_PATH, 'w', encoding='utf-8') as f:
        json.dump(snapshot, f, indent=2, ensure_ascii=False)
    
    # 2. è¿½åŠ  history.csv
    logger.info(f"ğŸ“ è¿½åŠ æ­·å²è¨˜éŒ„åˆ° {HISTORY_CSV_PATH}...")
    _append_history_csv(chain_data, cex_data, stablecoin_marketcap)


def _append_history_csv(chain_data: Dict, cex_data: Dict, stablecoin_marketcap: float):
    """
    è¿½åŠ ä¸€è¡Œåˆ° history.csv
    """
    # æå–æ‰€éœ€æ•¸æ“š
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # å¾ chain_data æå– Solana å’Œ Ethereum TVL
    solana_tvl = 0
    ethereum_tvl = 0
    for chain in chain_data.get('chains', []):
        if chain.get('chain') == 'solana':
            solana_tvl = chain.get('tvl_total', 0)
        elif chain.get('chain') == 'ethereum':
            ethereum_tvl = chain.get('tvl_total', 0)
    
    # å¾ cex_data æå– Binance æ·¨æµå…¥
    binance_net_flow = 0
    for exchange in cex_data.get('exchanges', []):
        if exchange.get('exchange') == 'binance-cex':
            binance_net_flow = exchange.get('net_flow_24h', 0)
            break
    
    # æ§‹å»ºè¡Œæ•¸æ“š
    row = {
        'Timestamp': timestamp,
        'Total_Stablecoin_MarketCap': stablecoin_marketcap,
        'Binance_Net_Flow': binance_net_flow,
        'Solana_TVL': solana_tvl,
        'Ethereum_TVL': ethereum_tvl
    }
    
    # æª¢æŸ¥ CSV æ˜¯å¦å­˜åœ¨
    file_exists = HISTORY_CSV_PATH.exists()
    
    with open(HISTORY_CSV_PATH, 'a', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=CSV_COLUMNS)
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯«å…¥æ¨™é¡Œè¡Œ
        if not file_exists:
            writer.writeheader()
        
        writer.writerow(row)
    
    logger.info(f"   â†’ å·²è¿½åŠ : Stablecoin ${stablecoin_marketcap/1e9:.1f}B, "
                f"Binance Flow ${binance_net_flow/1e6:+.1f}M, "
                f"SOL TVL ${solana_tvl/1e9:.1f}B, ETH TVL ${ethereum_tvl/1e9:.1f}B")


def main():
    """
    ä¸»å…¥å£
    """
    print("=" * 60)
    print("ğŸš€ è³‡é‡‘æµå‘æ•¸æ“šç®¡é“ (Capital Flow Pipeline)")
    print("=" * 60)
    
    snapshot = asyncio.run(run_pipeline())
    
    print("\n" + "=" * 60)
    print("ğŸ“Š åŸ·è¡Œçµæœæ‘˜è¦")
    print("=" * 60)
    # V2 Schema Output
    try:
        print(f"   å¸‚å ´æƒ…ç·’: {snapshot['market_overview']['sentiment']['label']}")
        print(f"   ç©©å®šå¹£å¸‚å€¼: ${snapshot['market_overview']['stablecoin_marketcap']/1e9:.1f}B")
        print(f"   åˆ†æå…¬éˆæ•¸: {snapshot['market_overview']['total_tvl']['dex']:.0f} (Total TVL)") # Simplify print
        print(f"   åˆ†æäº¤æ˜“æ‰€æ•¸: {snapshot['cex_analysis']['summary']['exchange_count']}")
    except KeyError:
        # Fallback for older schema or partial data
        print("   (Summary data format changed, check data.json)")
    
    print(f"   åŸ·è¡Œæ™‚é–“: {snapshot['meta']['execution_time_seconds']:.2f}s")
    print("=" * 60)
    print("ğŸ“ è¼¸å‡ºæ–‡ä»¶:")
    print(f"   â†’ {DATA_JSON_PATH}")
    print(f"   â†’ {HISTORY_CSV_PATH}")
    print("=" * 60)


if __name__ == '__main__':
    main()
