"""
ğŸš€ Main Pipeline - è³‡é‡‘æµå‘æ•¸æ“šç®¡é“ v1.0
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
åŠŸèƒ½ç‰¹è‰²ï¼š
- æ•´åˆ ChainAnalyzer å’Œ CEXAnalyzer åŸ·è¡Œåˆ†æ
- è¼¸å‡º data.json (å³æ™‚å¿«ç…§)
- è¿½åŠ  history.csv (æ­·å²æ•¸æ“šä¾›å›æ¸¬)
- ç´”æ•¸æ“šè¼¸å‡ºï¼Œç„¡ HTML ç”Ÿæˆ

è¼¸å‡ºï¼š
- reports/data.json: å®Œæ•´å¿«ç…§æ•¸æ“š
- reports/history.csv: æ­·å²è¿½è¹¤è¡Œ
"""

import asyncio
import json
import csv
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any

from data_provider import DataProvider
from analyzer_chain import ChainAnalyzer
from analyzer_cex import CEXAnalyzer
from notification_service import check_and_alert, send_summary_notification

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è¼¸å‡ºè·¯å¾‘
REPORTS_DIR = Path(__file__).parent / "reports"
DATA_JSON_PATH = REPORTS_DIR / "data.json"
HISTORY_CSV_PATH = REPORTS_DIR / "history.csv"

# åˆ†æçš„å…¬éˆåˆ—è¡¨
CHAINS_TO_ANALYZE = [
    'ethereum', 'solana', 'bsc', 'arbitrum', 'base',
    'polygon', 'avalanche', 'optimism', 'tron'
]

# CSV æ¬„ä½å®šç¾©
CSV_COLUMNS = [
    'Timestamp',
    'Total_Stablecoin_MarketCap',
    'Binance_Net_Flow',
    'Solana_TVL',
    'Ethereum_TVL'
]


async def run_pipeline() -> Dict[str, Any]:
    """
    åŸ·è¡Œå®Œæ•´æ•¸æ“šç®¡é“
    
    Returns:
        èšåˆå¾Œçš„æ•¸æ“šå¿«ç…§
    """
    logger.info("ğŸš€ å•Ÿå‹•è³‡é‡‘æµå‘æ•¸æ“šç®¡é“...")
    start_time = datetime.now()
    
    async with DataProvider() as provider:
        # 1. åŸ·è¡Œå…¬éˆåˆ†æ
        logger.info("ğŸ“Š åˆ†æå…¬éˆè³‡é‡‘æµå‘...")
        chain_analyzer = ChainAnalyzer(provider)
        chain_data = await chain_analyzer.analyze_multiple_chains(CHAINS_TO_ANALYZE)
        
        # 2. åŸ·è¡Œäº¤æ˜“æ‰€åˆ†æ
        logger.info("ğŸ¦ åˆ†æäº¤æ˜“æ‰€è³‡é‡‘æµå‘...")
        cex_analyzer = CEXAnalyzer(provider)
        cex_data = await cex_analyzer.analyze_multiple_exchanges()
        
        # 3. ç²å–ç©©å®šå¹£å¸‚å€¼
        logger.info("ğŸ’µ ç²å–ç©©å®šå¹£å¸‚å€¼...")
        stablecoin_marketcap = await _get_stablecoin_marketcap(provider)
    
    # 4. èšåˆæ•¸æ“š
    timestamp = datetime.now(timezone.utc).isoformat()
    
    snapshot = {
        'timestamp': timestamp,
        'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'market_sentiment': _determine_overall_sentiment(chain_data, cex_data),
        'chain_flows': chain_data,
        'cex_flows': cex_data,
        'stablecoin_marketcap': stablecoin_marketcap,
        'execution_time_seconds': (datetime.now() - start_time).total_seconds()
    }
    
    # 5. å„²å­˜è¼¸å‡º
    await _save_outputs(snapshot, chain_data, cex_data, stablecoin_marketcap)
    
    # 6. ç™¼é€ Discord é€šçŸ¥
    logger.info("ğŸ”” æª¢æŸ¥ä¸¦ç™¼é€ Discord è­¦å ±...")
    alerts_sent = check_and_alert(snapshot)
    if alerts_sent > 0:
        logger.info(f"   â†’ å·²ç™¼é€ {alerts_sent} å€‹è­¦å ±")
    
    # 7. ç™¼é€æ‘˜è¦é€šçŸ¥
    send_summary_notification(snapshot)
    
    logger.info(f"âœ… ç®¡é“åŸ·è¡Œå®Œæˆ ({snapshot['execution_time_seconds']:.2f}s)")
    
    return snapshot


async def _get_stablecoin_marketcap(provider: DataProvider) -> float:
    """
    ç²å–ç©©å®šå¹£ç¸½å¸‚å€¼
    """
    try:
        data = await provider.get_stablecoins()
        if data and 'peggedAssets' in data:
            total = 0
            for asset in data['peggedAssets']:
                circulating = asset.get('circulating', {})
                total += circulating.get('peggedUSD', 0) or 0
            return total
    except Exception as e:
        logger.warning(f"ç„¡æ³•ç²å–ç©©å®šå¹£å¸‚å€¼: {e}")
    return 0


def _determine_overall_sentiment(chain_data: Dict, cex_data: Dict) -> str:
    """
    ç¶œåˆåˆ¤æ–·å¸‚å ´æƒ…ç·’
    """
    chain_sentiment = chain_data.get('summary', {}).get('market_sentiment', 'Neutral')
    cex_sentiment = cex_data.get('summary', {}).get('market_sentiment', 'Neutral')
    
    # ç°¡å–®é‚è¼¯ï¼šå…©è€…éƒ½çœ‹æ¼² -> Bullishï¼Œéƒ½çœ‹è·Œ -> Bearishï¼Œå¦å‰‡ Neutral
    if chain_sentiment == 'Bullish' and cex_sentiment == 'Bullish':
        return 'Bullish'
    elif chain_sentiment == 'Bearish' and cex_sentiment == 'Bearish':
        return 'Bearish'
    elif chain_sentiment == 'Bullish' or cex_sentiment == 'Bullish':
        return 'Slightly Bullish'
    elif chain_sentiment == 'Bearish' or cex_sentiment == 'Bearish':
        return 'Slightly Bearish'
    return 'Neutral'


async def _save_outputs(
    snapshot: Dict, 
    chain_data: Dict, 
    cex_data: Dict, 
    stablecoin_marketcap: float
):
    """
    å„²å­˜è¼¸å‡ºæ–‡ä»¶
    """
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    REPORTS_DIR.mkdir(exist_ok=True)
    
    # 1. å„²å­˜ data.json
    logger.info(f"ğŸ’¾ å„²å­˜å¿«ç…§åˆ° {DATA_JSON_PATH}...")
    with open(DATA_JSON_PATH, 'w', encoding='utf-8') as f:
        json.dump(snapshot, f, indent=2, ensure_ascii=False)
    
    # 2. è¿½åŠ  history.csv
    logger.info(f"ğŸ“ è¿½åŠ æ­·å²è¨˜éŒ„åˆ° {HISTORY_CSV_PATH}...")
    _append_history_csv(chain_data, cex_data, stablecoin_marketcap)


def _append_history_csv(chain_data: Dict, cex_data: Dict, stablecoin_marketcap: float):
    """
    è¿½åŠ ä¸€è¡Œåˆ° history.csv
    """
    # æå–æ‰€éœ€æ•¸æ“š
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # å¾ chain_data æå– Solana å’Œ Ethereum TVL
    solana_tvl = 0
    ethereum_tvl = 0
    for chain in chain_data.get('chains', []):
        if chain.get('chain') == 'solana':
            solana_tvl = chain.get('tvl_total', 0)
        elif chain.get('chain') == 'ethereum':
            ethereum_tvl = chain.get('tvl_total', 0)
    
    # å¾ cex_data æå– Binance æ·¨æµå…¥
    binance_net_flow = 0
    for exchange in cex_data.get('exchanges', []):
        if exchange.get('exchange') == 'binance-cex':
            binance_net_flow = exchange.get('net_flow_24h', 0)
            break
    
    # æ§‹å»ºè¡Œæ•¸æ“š
    row = {
        'Timestamp': timestamp,
        'Total_Stablecoin_MarketCap': stablecoin_marketcap,
        'Binance_Net_Flow': binance_net_flow,
        'Solana_TVL': solana_tvl,
        'Ethereum_TVL': ethereum_tvl
    }
    
    # æª¢æŸ¥ CSV æ˜¯å¦å­˜åœ¨
    file_exists = HISTORY_CSV_PATH.exists()
    
    with open(HISTORY_CSV_PATH, 'a', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=CSV_COLUMNS)
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯«å…¥æ¨™é¡Œè¡Œ
        if not file_exists:
            writer.writeheader()
        
        writer.writerow(row)
    
    logger.info(f"   â†’ å·²è¿½åŠ : Stablecoin ${stablecoin_marketcap/1e9:.1f}B, "
                f"Binance Flow ${binance_net_flow/1e6:+.1f}M, "
                f"SOL TVL ${solana_tvl/1e9:.1f}B, ETH TVL ${ethereum_tvl/1e9:.1f}B")


def main():
    """
    ä¸»å…¥å£
    """
    print("=" * 60)
    print("ğŸš€ è³‡é‡‘æµå‘æ•¸æ“šç®¡é“ (Capital Flow Pipeline)")
    print("=" * 60)
    
    snapshot = asyncio.run(run_pipeline())
    
    print("\n" + "=" * 60)
    print("ğŸ“Š åŸ·è¡Œçµæœæ‘˜è¦")
    print("=" * 60)
    print(f"   å¸‚å ´æƒ…ç·’: {snapshot['market_sentiment']}")
    print(f"   ç©©å®šå¹£å¸‚å€¼: ${snapshot['stablecoin_marketcap']/1e9:.1f}B")
    print(f"   åˆ†æå…¬éˆæ•¸: {len(snapshot['chain_flows'].get('chains', []))}")
    print(f"   åˆ†æäº¤æ˜“æ‰€æ•¸: {len(snapshot['cex_flows'].get('exchanges', []))}")
    print(f"   åŸ·è¡Œæ™‚é–“: {snapshot['execution_time_seconds']:.2f}s")
    print("=" * 60)
    print(f"ğŸ“ è¼¸å‡ºæ–‡ä»¶:")
    print(f"   â†’ {DATA_JSON_PATH}")
    print(f"   â†’ {HISTORY_CSV_PATH}")
    print("=" * 60)


if __name__ == '__main__':
    main()
