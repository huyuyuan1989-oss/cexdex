"""
ğŸš€ Main Pipeline - è³‡é‡‘æµå‘æ•¸æ“šç®¡é“ v1.0
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
åŠŸèƒ½ç‰¹è‰²ï¼š
- æ•´åˆ ChainAnalyzer å’Œ CEXAnalyzer åŸ·è¡Œåˆ†æ
- è¼¸å‡º data.json (å³æ™‚å¿«ç…§)
- è¿½åŠ  history.csv (æ­·å²æ•¸æ“šä¾›å›æ¸¬)
- ç´”æ•¸æ“šè¼¸å‡ºï¼Œç„¡ HTML ç”Ÿæˆ

è¼¸å‡ºï¼š
- reports/data.json: å®Œæ•´å¿«ç…§æ•¸æ“š
- reports/history.csv: æ­·å²è¿½è¹¤è¡Œ
"""

import asyncio
import json
import csv
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any

from data_provider import DataProvider
from analyzer_chain import ChainAnalyzer
from analyzer_cex import CEXAnalyzer
from notification_service import check_and_alert, send_summary_notification

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è¼¸å‡ºè·¯å¾‘
REPORTS_DIR = Path(__file__).parent / "reports"
DATA_JSON_PATH = REPORTS_DIR / "data.json"
HISTORY_CSV_PATH = REPORTS_DIR / "history.csv"

# åˆ†æçš„å…¬éˆåˆ—è¡¨
CHAINS_TO_ANALYZE = [
    'ethereum', 'solana', 'bsc', 'arbitrum', 'base',
    'polygon', 'avalanche', 'optimism', 'tron'
]

# CSV æ¬„ä½å®šç¾©
CSV_COLUMNS = [
    'Timestamp',
    'Total_Stablecoin_MarketCap',
    'Binance_Net_Flow',
    'Solana_TVL',
    'Ethereum_TVL'
]


async def run_pipeline() -> Dict[str, Any]:
    """
    åŸ·è¡Œå®Œæ•´æ•¸æ“šç®¡é“
    
    Returns:
        èšåˆå¾Œçš„æ•¸æ“šå¿«ç…§
    """
    logger.info("ğŸš€ å•Ÿå‹•è³‡é‡‘æµå‘æ•¸æ“šç®¡é“...")
    start_time = datetime.now()
    
    async with DataProvider() as provider:
        # 1. åŸ·è¡Œå…¬éˆåˆ†æ
        logger.info("ğŸ“Š åˆ†æå…¬éˆè³‡é‡‘æµå‘...")
        chain_analyzer = ChainAnalyzer(provider)
        chain_data = await chain_analyzer.analyze_multiple_chains(CHAINS_TO_ANALYZE)
        
        # 2. åŸ·è¡Œäº¤æ˜“æ‰€åˆ†æ
        logger.info("ğŸ¦ åˆ†æäº¤æ˜“æ‰€è³‡é‡‘æµå‘...")
        cex_analyzer = CEXAnalyzer(provider)
        cex_data = await cex_analyzer.analyze_multiple_exchanges()
        
        # 3. ç²å–ç©©å®šå¹£å¸‚å€¼
        logger.info("ğŸ’µ ç²å–ç©©å®šå¹£å¸‚å€¼...")
        stablecoin_marketcap = await _get_stablecoin_marketcap(provider)

        # 4. ç²å–è¡ç”Ÿå“æ•¸æ“š (Institutional Grade)
        logger.info("ğŸ“ˆ ç²å–è¡ç”Ÿå“æ•¸æ“š (Funding/OI)...")
        derivs_data = await provider.get_derivatives_data()
    
    # 5. ç”Ÿæˆçµ±ä¸€å ±å‘Š
    from report_generator import ReportGenerator
    
    logger.info("ğŸ“ ç”Ÿæˆçµ±ä¸€å ±å‘Š (V2 Schema)...")
    generator = ReportGenerator()
    unified_report = generator.generate_unified_report(
        chain_data=chain_data,
        cex_data=cex_data,
        sentiment_details=_calculate_sentiment_score(chain_data, cex_data),
        stablecoin_marketcap=stablecoin_marketcap,
        derivs_data=derivs_data  # Pass new data
    )
    
    # æ·»åŠ åŸ·è¡Œæ™‚é–“
    unified_report['meta']['execution_time_seconds'] = (datetime.now() - start_time).total_seconds()
    
    # 5. å„²å­˜è¼¸å‡º
    await _save_outputs(unified_report, chain_data, cex_data, stablecoin_marketcap)
    
    # 6. ç™¼é€ Discord é€šçŸ¥
    logger.info("ğŸ”” æª¢æŸ¥ä¸¦ç™¼é€ Discord è­¦å ±...")
    alerts_sent = check_and_alert(unified_report)  # ç¢ºä¿ check_and_alert èƒ½è™•ç†æ–°æ ¼å¼
    if alerts_sent > 0:
        logger.info(f"   â†’ å·²ç™¼é€ {alerts_sent} å€‹è­¦å ±")
    
    # 7. ç™¼é€æ‘˜è¦é€šçŸ¥
    send_summary_notification(unified_report)
    
    logger.info(f"âœ… ç®¡é“åŸ·è¡Œå®Œæˆ ({unified_report['meta']['execution_time_seconds']:.2f}s)")
    
    return unified_report


async def _get_stablecoin_marketcap(provider: DataProvider) -> float:
    """
    ç²å–ç©©å®šå¹£ç¸½å¸‚å€¼
    """
    try:
        data = await provider.get_stablecoins()
        if data and 'peggedAssets' in data:
            total = 0
            for asset in data['peggedAssets']:
                circulating = asset.get('circulating', {})
                total += circulating.get('peggedUSD', 0) or 0
            return total
    except Exception as e:
        logger.warning(f"ç„¡æ³•ç²å–ç©©å®šå¹£å¸‚å€¼: {e}")
    return 0


def _calculate_sentiment_score(chain_data: Dict, cex_data: Dict) -> Dict[str, Any]:
    """
    åŠ æ¬Šæƒ…ç·’è©•åˆ†ç³»çµ± (å„ªåŒ–ç‰ˆ)
    
    Returns:
        {
            'score': -100 to +100,
            'label': 'Strong Bullish' | 'Bullish' | 'Neutral' | 'Bearish' | 'Strong Bearish',
            'factors': [{name, weight, impact, reason}, ...]
        }
    """
    factors = []
    total_score = 0
    
    # === Factor 1: å…¬éˆç©©å®šå¹£æµå…¥ (æ¬Šé‡ 30%) ===
    chain_summary = chain_data.get('summary', {})
    stable_inflow = chain_summary.get('total_stable_inflow_24h', 0)
    
    if stable_inflow > 100_000_000:  # > $100M æµå…¥
        impact = min(30, int(stable_inflow / 100_000_000 * 10))
        factors.append({
            'name': 'Chain Stablecoin Inflow',
            'weight': 0.3,
            'impact': impact,
            'reason': f'ç©©å®šå¹£æµå…¥ ${stable_inflow/1e6:.1f}M (è²·ç›¤è³‡é‡‘)'
        })
        total_score += impact
    elif stable_inflow < -100_000_000:  # > $100M æµå‡º
        impact = max(-30, int(stable_inflow / 100_000_000 * 10))
        factors.append({
            'name': 'Chain Stablecoin Outflow',
            'weight': 0.3,
            'impact': impact,
            'reason': f'ç©©å®šå¹£æµå‡º ${abs(stable_inflow)/1e6:.1f}M (è³‡é‡‘æ’¤é›¢)'
        })
        total_score += impact
    
    # === Factor 2: äº¤æ˜“æ‰€ BTC/ETH æµå…¥ (æ¬Šé‡ 30%) ===
    cex_summary = cex_data.get('summary', {})
    btc_eth_flow = cex_summary.get('total_btc_eth_flow_24h', 0)
    
    if btc_eth_flow > 50_000_000:  # BTC/ETH å¤§é‡æµå…¥äº¤æ˜“æ‰€ = è³£å£“
        impact = max(-30, int(-btc_eth_flow / 50_000_000 * 10))
        factors.append({
            'name': 'CEX BTC/ETH Inflow',
            'weight': 0.3,
            'impact': impact,
            'reason': f'BTC/ETH æµå…¥äº¤æ˜“æ‰€ ${btc_eth_flow/1e6:.1f}M (æ½›åœ¨è³£å£“)'
        })
        total_score += impact
    elif btc_eth_flow < -50_000_000:  # BTC/ETH æµå‡ºäº¤æ˜“æ‰€ = å›¤è²¨
        impact = min(30, int(-btc_eth_flow / 50_000_000 * 10))
        factors.append({
            'name': 'CEX BTC/ETH Outflow',
            'weight': 0.3,
            'impact': impact,
            'reason': f'BTC/ETH æµå‡ºäº¤æ˜“æ‰€ ${abs(btc_eth_flow)/1e6:.1f}M (å›¤è²¨ä¿¡è™Ÿ)'
        })
        total_score += impact
    
    # === Factor 3: ä¿¡è™Ÿæ•¸é‡æ¯”è¼ƒ (æ¬Šé‡ 20%) ===
    chain_bullish = chain_summary.get('bullish_signals', 0)
    chain_bearish = chain_summary.get('bearish_signals', 0)
    cex_bullish = cex_summary.get('bullish_signals', 0)
    cex_bearish = cex_summary.get('bearish_signals', 0)
    
    total_bullish = chain_bullish + cex_bullish
    total_bearish = chain_bearish + cex_bearish
    
    signal_diff = total_bullish - total_bearish
    if signal_diff != 0:
        impact = min(20, max(-20, signal_diff * 5))
        factors.append({
            'name': 'Signal Balance',
            'weight': 0.2,
            'impact': impact,
            'reason': f'{total_bullish} çœ‹å¤šä¿¡è™Ÿ vs {total_bearish} çœ‹ç©ºä¿¡è™Ÿ'
        })
        total_score += impact
    
    # === Factor 4: ç©©å®šå¹£æµå…¥äº¤æ˜“æ‰€ (æ¬Šé‡ 20%) ===
    cex_stable_flow = cex_summary.get('total_stablecoin_flow_24h', 0)
    
    if cex_stable_flow > 100_000_000:  # ç©©å®šå¹£æµå…¥äº¤æ˜“æ‰€ = æ½›åœ¨è²·ç›¤
        impact = min(20, int(cex_stable_flow / 100_000_000 * 8))
        factors.append({
            'name': 'CEX Stablecoin Inflow',
            'weight': 0.2,
            'impact': impact,
            'reason': f'ç©©å®šå¹£æµå…¥äº¤æ˜“æ‰€ ${cex_stable_flow/1e6:.1f}M (å‚™æˆ°è²·å…¥)'
        })
        total_score += impact
    elif cex_stable_flow < -100_000_000:  # ç©©å®šå¹£æµå‡º = æ¸›å°‘è²·ç›¤
        impact = max(-20, int(cex_stable_flow / 100_000_000 * 8))
        factors.append({
            'name': 'CEX Stablecoin Outflow',
            'weight': 0.2,
            'impact': impact,
            'reason': f'ç©©å®šå¹£æµå‡ºäº¤æ˜“æ‰€ ${abs(cex_stable_flow)/1e6:.1f}M (è²·ç›¤æ¸›å°‘)'
        })
        total_score += impact
    
    # é™åˆ¶åˆ†æ•¸ç¯„åœ
    total_score = max(-100, min(100, total_score))
    
    # è½‰æ›ç‚ºæ¨™ç±¤
    if total_score >= 40:
        label = 'Strong Bullish'
    elif total_score >= 15:
        label = 'Bullish'
    elif total_score <= -40:
        label = 'Strong Bearish'
    elif total_score <= -15:
        label = 'Bearish'
    else:
        label = 'Neutral'
    
    return {
        'score': total_score,
        'label': label,
        'factors': factors
    }


def _determine_overall_sentiment(chain_data: Dict, cex_data: Dict) -> str:
    """
    ç¶œåˆåˆ¤æ–·å¸‚å ´æƒ…ç·’ (å‘å¾Œå…¼å®¹åŒ…è£å‡½æ•¸)
    """
    result = _calculate_sentiment_score(chain_data, cex_data)
    return result['label']


async def _save_outputs(
    snapshot: Dict, 
    chain_data: Dict, 
    cex_data: Dict, 
    stablecoin_marketcap: float
):
    """
    å„²å­˜è¼¸å‡ºæ–‡ä»¶
    """
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    REPORTS_DIR.mkdir(exist_ok=True)
    
    # 1. å„²å­˜ data.json
    logger.info(f"ğŸ’¾ å„²å­˜å¿«ç…§åˆ° {DATA_JSON_PATH}...")
    with open(DATA_JSON_PATH, 'w', encoding='utf-8') as f:
        json.dump(snapshot, f, indent=2, ensure_ascii=False)
    
    # 2. è¿½åŠ  history.csv
    logger.info(f"ğŸ“ è¿½åŠ æ­·å²è¨˜éŒ„åˆ° {HISTORY_CSV_PATH}...")
    _append_history_csv(chain_data, cex_data, stablecoin_marketcap)


def _append_history_csv(chain_data: Dict, cex_data: Dict, stablecoin_marketcap: float):
    """
    è¿½åŠ ä¸€è¡Œåˆ° history.csv
    """
    # æå–æ‰€éœ€æ•¸æ“š
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # å¾ chain_data æå– Solana å’Œ Ethereum TVL
    solana_tvl = 0
    ethereum_tvl = 0
    for chain in chain_data.get('chains', []):
        if chain.get('chain') == 'solana':
            solana_tvl = chain.get('tvl_total', 0)
        elif chain.get('chain') == 'ethereum':
            ethereum_tvl = chain.get('tvl_total', 0)
    
    # å¾ cex_data æå– Binance æ·¨æµå…¥
    binance_net_flow = 0
    for exchange in cex_data.get('exchanges', []):
        if exchange.get('exchange') == 'binance-cex':
            binance_net_flow = exchange.get('net_flow_24h', 0)
            break
    
    # æ§‹å»ºè¡Œæ•¸æ“š
    row = {
        'Timestamp': timestamp,
        'Total_Stablecoin_MarketCap': stablecoin_marketcap,
        'Binance_Net_Flow': binance_net_flow,
        'Solana_TVL': solana_tvl,
        'Ethereum_TVL': ethereum_tvl
    }
    
    # æª¢æŸ¥ CSV æ˜¯å¦å­˜åœ¨
    file_exists = HISTORY_CSV_PATH.exists()
    
    with open(HISTORY_CSV_PATH, 'a', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=CSV_COLUMNS)
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯«å…¥æ¨™é¡Œè¡Œ
        if not file_exists:
            writer.writeheader()
        
        writer.writerow(row)
    
    logger.info(f"   â†’ å·²è¿½åŠ : Stablecoin ${stablecoin_marketcap/1e9:.1f}B, "
                f"Binance Flow ${binance_net_flow/1e6:+.1f}M, "
                f"SOL TVL ${solana_tvl/1e9:.1f}B, ETH TVL ${ethereum_tvl/1e9:.1f}B")


def main():
    """
    ä¸»å…¥å£
    """
    print("=" * 60)
    print("ğŸš€ è³‡é‡‘æµå‘æ•¸æ“šç®¡é“ (Capital Flow Pipeline)")
    print("=" * 60)
    
    snapshot = asyncio.run(run_pipeline())
    
    print("\n" + "=" * 60)
    print("ğŸ“Š åŸ·è¡Œçµæœæ‘˜è¦")
    print("=" * 60)
    # V2 Schema Output
    try:
        print(f"   å¸‚å ´æƒ…ç·’: {snapshot['market_overview']['sentiment']['label']}")
        print(f"   ç©©å®šå¹£å¸‚å€¼: ${snapshot['market_overview']['stablecoin_marketcap']/1e9:.1f}B")
        print(f"   åˆ†æå…¬éˆæ•¸: {snapshot['market_overview']['total_tvl']['dex']:.0f} (Total TVL)") # Simplify print
        print(f"   åˆ†æäº¤æ˜“æ‰€æ•¸: {snapshot['cex_analysis']['summary']['exchange_count']}")
    except KeyError:
        # Fallback for older schema or partial data
        print("   (Summary data format changed, check data.json)")
    
    print(f"   åŸ·è¡Œæ™‚é–“: {snapshot['meta']['execution_time_seconds']:.2f}s")
    print("=" * 60)
    print("ğŸ“ è¼¸å‡ºæ–‡ä»¶:")
    print(f"   â†’ {DATA_JSON_PATH}")
    print(f"   â†’ {HISTORY_CSV_PATH}")
    print("=" * 60)


if __name__ == '__main__':
    main()
